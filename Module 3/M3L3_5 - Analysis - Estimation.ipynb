{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95478a64",
   "metadata": {},
   "source": [
    "## Introduction to Estimation\n",
    "\n",
    "Estimation is a branch of the Analysis Phase to use when you are testing for a continuous variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23158167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Workshop Functions\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Wksp722_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add70932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eea58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cb2d6",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Let's try to replace the missing 'total_bedrooms' column with the median value for that variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d525225",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing.loc[:,\"total_bedrooms\"].median()\n",
    "housing.loc[:,\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1e603",
   "metadata": {},
   "source": [
    "Next, let's look at the variables and see how they're correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=housing.corr(numeric_only=True)\n",
    "corr_matrix.median_house_value.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e0ca8",
   "metadata": {},
   "source": [
    "It looks like 'median_income' has a high correlation to the median_house_value.  \n",
    "\n",
    "Another Kaggle user created a new variable by dividing the total_rooms and total_bedrooms by households.  On their own, total_rooms, total_bedrooms and households are good indicators of housing density in an area.  The new normalized values give the number of rooms and bedrooms per household, which can be a better indicator of house side.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.loc[:,'rooms_per_household'] = housing.loc[:,'total_rooms']/housing.loc[:,'households']\n",
    "housing.loc[:,'bedrooms_per_household'] = housing.loc[:,'total_bedrooms']/housing.loc[:,'households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3dbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run correlation\n",
    "corr_matrix=housing.corr(numeric_only=True)\n",
    "corr_matrix.median_house_value.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b4479",
   "metadata": {},
   "source": [
    "The 'rooms_per_household' had a high correlation to the median_house_value.  This *may* be useful to analyses models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84170d3a",
   "metadata": {},
   "source": [
    "Lattitude also has a high correlation value.  I'm using code from a Kaggle notebook found here: https://www.kaggle.com/code/mostafaashraf1/california-housing-prices\n",
    "\n",
    "The map shows clustering of high value homes around the coast between San Fransciso and San Diego.  These are also highly populated areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1d238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M3L4_CA_plot(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Convert ocean_proximity to numerical columns using One-Hot encoding\n",
    "dfTemp = pd.get_dummies(housing.loc[:,'ocean_proximity'])\n",
    "\n",
    "housing = pd.concat([housing,dfTemp], axis=1)\n",
    "housing.drop('ocean_proximity', axis=1,inplace=True)\n",
    "housing.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6081ed5",
   "metadata": {},
   "source": [
    "### Normalizing variables\n",
    "Some estimation algorithms require normally distributed variables.  We can use the RobustScaler function in Scikit-learn to normalize the variables.  But first, let's take a look at the distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15848ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50,figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5e080",
   "metadata": {},
   "source": [
    "We see that the distributions that seem to follow a Gaussian distribution (total_rooms, total_bedrooms, population, households, median_income, median_house_value), but have a longer right side tail.  RobustScaler will remove the median and scale the variance.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9168c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = housing.drop(columns=\"median_house_value\")\n",
    "y = housing.loc[:,'median_house_value']\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "ro_scaler = RobustScaler()\n",
    "housingScaled = ro_scaler.fit_transform(x) #<-- only scale the input variables, not the target\n",
    "\n",
    "housingScaled = pd.DataFrame(housingScaled, columns=x.columns)\n",
    "housingScaled.hist(bins=50,figsize=(20,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f42f40",
   "metadata": {},
   "source": [
    "While the distribution shapes for each variable have remained the same, the ranges have been adjusted to account for the longer tails and each variable has been normalized.  \n",
    "\n",
    "We are now ready to work on the estimation algorithms:\n",
    "* Linear Regression\n",
    "* Decision Tree\n",
    "* Random Forest (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f174a",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression().fit(x_train,y_train)\n",
    "y_pred_LR = LR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse_LR = np.sqrt(mean_squared_error(y_pred_LR, y_test))\n",
    "R2_LR = r2_score(y_pred_LR, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the actual vs predicted values\n",
    "M3L4_Predicted_Plot(x_test, y_test, y_pred_LR, numPts = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeef72c",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "First let's start with a small decision tree so we can take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Tree = DecisionTreeRegressor(random_state=1, max_depth=3).fit(x_train, y_train)\n",
    "y_pred_Tree = Tree.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('RMSE = ',np.sqrt(mean_squared_error(y_pred_Tree, y_test)))\n",
    "print('R2 = ', r2_score(y_pred_Tree, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(Tree,feature_names=x_test.columns)\n",
    "\n",
    "fig.savefig('treeRegression.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592cf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree - Full Length\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Tree = DecisionTreeRegressor(random_state=1, max_depth=None).fit(x_train, y_train)\n",
    "y_pred_Tree = Tree.predict(x_test)\n",
    "\n",
    "rmse_Tree = np.sqrt(mean_squared_error(y_pred_Tree, y_test))\n",
    "R2_Tree = r2_score(y_pred_Tree, y_test)\n",
    "\n",
    "print('mean house price = ', y_test.mean())\n",
    "print(rmse_Tree, R2_Tree)\n",
    "print('max tree depth = ', Tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor(n_estimators = 100, max_depth=None, random_state=1)\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred_RF = RF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse_RF = np.sqrt(mean_squared_error(y_pred_RF, y_test))\n",
    "R2_RF = r2_score(y_pred_RF, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbfab41",
   "metadata": {},
   "source": [
    "#### Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Estimator':['Linear Regression', 'Decision Tree','Random Forest'],\n",
    "       'RMSE':[rmse_LR, rmse_Tree,rmse_RF],\n",
    "       'R2 Score':[R2_LR, R2_Tree, R2_RF]}\n",
    "\n",
    "EstimationMetrics = pd.DataFrame(data)\n",
    "#print(EstimationMetrics)\n",
    "display(EstimationMetrics) #<--- Nicer alternative to print for dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d3905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
